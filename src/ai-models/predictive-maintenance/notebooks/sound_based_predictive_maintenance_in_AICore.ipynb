{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fc96bb",
   "metadata": {},
   "source": [
    "# Sound Based Predictive Maintenance in SAP AI Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc08df-eb9d-43f9-a1a6-84e6f918f5d0",
   "metadata": {},
   "source": [
    "In this notebook we will walk through the process of training and deploying a sound classification deep learning model in SAP AI Core."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9123a4-3213-46ec-8cb5-1b237a1de50c",
   "metadata": {},
   "source": [
    "## Create an AI API client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08f2504-e91d-401d-bf1f-26ceaf654597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_api_client_sdk.ai_api_v2_client import AIAPIV2Client\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81fc74-c054-4cf2-b7b7-b00265b6e6c1",
   "metadata": {},
   "source": [
    "First of all, we need to create an AI API client instance, which will allow us to interact with our SAP AI Core tenant. Before executing the code, edit the [aic_bootcamp_service_key.json](../files/aic_bootcamp_service_key.json) file and enter the urls and keys of your tenant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ae9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your service key JSON file relative to your aicore instance\n",
    "aic_service_key_path = '../files/aic_bootcamp_service_key.json'\n",
    "\n",
    "# Loads the service key file\n",
    "with open(aic_service_key_path) as ask:\n",
    "    aic_service_key = json.load(ask)\n",
    "\n",
    "# Creating an AI API client instance\n",
    "ai_api_client = AIAPIV2Client(\n",
    "    base_url = aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\", # The present AI API version is 2\n",
    "    auth_url=  aic_service_key[\"url\"] + \"/oauth/token\",\n",
    "    client_id = aic_service_key['clientid'],\n",
    "    client_secret = aic_service_key['clientsecret']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0e57c",
   "metadata": {},
   "source": [
    "## 1. Create a Resource Group and Connect AWS S3 to SAP AI Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc092d19",
   "metadata": {},
   "source": [
    "Resource Groups represent a virtual collection of related resources within the scope of one SAP AI Core tenant. Let's create a specific resource group for our sound classification exercise. That resource group will then appear also on the AI Lauchpad UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8eeee3-91ab-4216-a784-da689d9c10cd",
   "metadata": {},
   "source": [
    "### List existing resource groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017c4f3a-1d5e-4500-aa31-c1ffa7423d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'sound', 'message': 'Resource Group deletion scheduled'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_api_client.rest_client.delete(\n",
    "    path=f\"/admin/resourceGroups/sound\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f85835-e557-43f4-a5dd-23139d0abd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 2,\n",
       " 'resources': [{'created_at': '2022-04-23T12:12:00+00:00',\n",
       "   'labels': [],\n",
       "   'resource_group_id': 'defect-det-calabria',\n",
       "   'status': 'PROVISIONED',\n",
       "   'status_message': 'All onboarding steps are completed.',\n",
       "   'tenant_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc',\n",
       "   'zone_id': ''},\n",
       "  {'created_at': '2022-04-20T03:21:15+00:00',\n",
       "   'labels': [],\n",
       "   'resource_group_id': 'default',\n",
       "   'status': 'PROVISIONED',\n",
       "   'status_message': 'All onboarding steps are completed.',\n",
       "   'tenant_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc',\n",
       "   'zone_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_api_client.rest_client.get(\n",
    "    path=f\"/admin/resourceGroups\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1c2d5-69d3-4fe3-9782-0ad9935f5aa3",
   "metadata": {},
   "source": [
    "### Create a new resource group for sound classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f75fb0-3392-4e57-8c56-023c70e0ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group='soundU0001' #!!! to be modified according to your username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c33993d-bb6c-44c8-9f98-3b2ebbfcc3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resource_group_id': 'soundU0001',\n",
       " 'tenant_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc',\n",
       " 'zone_id': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_api_client.rest_client.post(\n",
    "    path=\"/admin/resourceGroups\",\n",
    "    body={\n",
    "        \"resourceGroupId\": resource_group # Name of your resource group\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d9d686-689e-4e24-9f86-b31ad7992656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 3,\n",
       " 'resources': [{'created_at': '2022-04-23T12:12:00+00:00',\n",
       "   'labels': [],\n",
       "   'resource_group_id': 'defect-det-calabria',\n",
       "   'status': 'PROVISIONED',\n",
       "   'status_message': 'All onboarding steps are completed.',\n",
       "   'tenant_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc',\n",
       "   'zone_id': ''},\n",
       "  {'created_at': '2022-04-20T03:21:15+00:00',\n",
       "   'labels': [],\n",
       "   'resource_group_id': 'default',\n",
       "   'status': 'PROVISIONED',\n",
       "   'status_message': 'All onboarding steps are completed.',\n",
       "   'tenant_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc',\n",
       "   'zone_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc'},\n",
       "  {'created_at': '2022-05-09T10:00:28+00:00',\n",
       "   'labels': [],\n",
       "   'resource_group_id': 'soundU0001',\n",
       "   'status': 'PROVISIONED',\n",
       "   'status_message': 'All onboarding steps are completed.',\n",
       "   'tenant_id': 'dcf5ea6e-9b13-47d7-9486-747429386dfc',\n",
       "   'zone_id': ''}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_api_client.rest_client.get(\n",
    "    path=f\"/admin/resourceGroups\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e40c7-0c00-44f4-be14-2611ded3f836",
   "metadata": {},
   "source": [
    "We are using AWS S3 Object Store as a cloud storage for our AI Core datasets and models. \n",
    "You can get AWS S3 Bucket from either of two ways:\n",
    "\n",
    "- through SAP BTP Cockpit;\n",
    "\n",
    "- through AWS. Refer AWS User Guide to S3.\n",
    "\n",
    "For this exercise, we have already loaded our input dataset on a S3 Storage bucket for you. If you had to do this on your own, you would need to install AWS CLI and upload your dataset by means of a command like the following:\n",
    "    aws s3 cp --recursive /local/path/to/data s3://your-bucket-id/sound/data/\n",
    "\n",
    "Once the data are in the AWS S3, we need to register the Object Store to SAP AI Core resource group. In order to to that we prepare a json file with the needed AWS S3 credentials and we use a proper AI API in order to register it. Please enter your AWS S3 Object Store credentials in [s3_service_key.json](../files/s3_service_key.json) before executing the code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9225c-6984-4f3a-99f6-0dc2d19667cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads your service key\n",
    "s3_service_key_path = '../files/s3_service_key.json'\n",
    "\n",
    "# Loads the service key file\n",
    "with open(s3_service_key_path) as s3sk:\n",
    "    s3_service_key = json.load(s3sk)\n",
    "\n",
    "default_secret = {\n",
    "    \"name\": \"default\", # Name of the connection\n",
    "    \"type\": \"S3\",\n",
    "    \"endpoint\": s3_service_key[\"host\"],\n",
    "    \"bucket\": s3_service_key[\"bucket\"],\n",
    "    \"pathPrefix\": \"sound\",\n",
    "    \"region\": s3_service_key[\"region\"],\n",
    "    \"data\": {\n",
    "        \"AWS_ACCESS_KEY_ID\": s3_service_key[\"access_key_id\"],\n",
    "        \"AWS_SECRET_ACCESS_KEY\": s3_service_key[\"secret_access_key\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Call the api\n",
    "ai_api_client.rest_client.post(\n",
    "    path=\"/admin/objectStoreSecrets\",\n",
    "    body = default_secret, # defined above\n",
    "    resource_group = resource_group\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa588c84",
   "metadata": {},
   "source": [
    "Let's make an API call to check if the artifact was corretly created. Object store secrets are stored under /admin/objectStoreSecrets and are linked to the resource group \"sound\", so those parameters have to be provided when creating and listing them. In case, with a similar call, secrets can be also deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_api_client.rest_client.get(\n",
    "    path=\"/admin/objectStoreSecrets\",\n",
    "    resource_group = resource_group\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc4bec-d890-4d5b-b960-a032ccaa7594",
   "metadata": {},
   "source": [
    "## 2. Train Sound Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12d53d-1a8f-429d-8386-f322745b113c",
   "metadata": {},
   "source": [
    "### 2.1 Create training docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004457d5-71d1-4ae4-a6b3-374e3bdf3c7e",
   "metadata": {},
   "source": [
    "In order to execute a training pipeline in AI Core, you need to dockerize your training code and push the docker image to your docker registry. You should have already linked your docker registrey to SAP AI Core during the previous exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a1405d-f893-4551-875e-03b203f07b85",
   "metadata": {},
   "source": [
    "### 2.2 Register training workflow as an application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54c74c-eb94-4402-89d7-2569bacdc479",
   "metadata": {},
   "source": [
    "After having prepared the docker image, you need to create a training workflow in the github repository associated to our AI Core instance. The yaml file needs to be uploaded in a dedicated folder of the github repo. You can then register your application using the AI API as follows. Before executing the code, open files/git_setup.json and double check everything is configured correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fc0bd-3ddc-4293-a5b7-f7a621ffb240",
   "metadata": {},
   "source": [
    "#### List available repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc579f53-4d22-435d-b016-f3aea657c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_api_client.rest_client.get(\n",
    "    path=\"/admin/repositories\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b8f1d-d709-41d3-b6b6-1e88ca0cf412",
   "metadata": {},
   "source": [
    "#### List available applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2577d4-f8b4-4d4b-8e24-3c915de3a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_api_client.rest_client.get(\n",
    "    path=\"/admin/applications\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d557f-f7ab-4b1d-bc4e-237a2714a31f",
   "metadata": {},
   "source": [
    "#### Add a new application for sound classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46b52f-5496-4dfc-b7ca-3617cce36370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads your git_setup.json\n",
    "with open('../files/git_setup.json') as gs:\n",
    "    setup_json = json.load(gs)\n",
    "    \n",
    "# Registers the directory as app\n",
    "app_json = setup_json[\"app\"]\n",
    "response = ai_api_client.rest_client.post(\n",
    "    path=\"/admin/applications\",\n",
    "    body={\n",
    "        \"applicationName\": app_json[\"applicationName\"],\n",
    "        \"repositoryUrl\": app_json[\"repositoryUrl\"],\n",
    "        \"revision\": app_json[\"revision\"],\n",
    "        \"path\": app_json[\"path\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43945f4a-2e99-4675-bb8c-3d8c97cd56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_api_client.rest_client.get(\n",
    "    path=\"/admin/applications\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731c4f3-7fb1-45f8-937c-4f5af40c2445",
   "metadata": {},
   "source": [
    "It is always a good practice to check the synchronization of the workflows (registered as apps), that are read from the registered GitHub repository. \n",
    "Please, keep in mind that the synchronization is triggered by any change to the yaml files pushed to GitHub and that AI Core checks every 3 minutes for new files or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77715035-c26f-4c7a-a835-45b800d3fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = \"aicore-sound\"\n",
    "\n",
    "ai_api_client.rest_client.get(\n",
    "    path=f\"/admin/applications/{app_name}/status\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1e473",
   "metadata": {},
   "source": [
    "### 2.3 - Choose a scenario  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import yaml\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "\n",
    "from ai_api_client_sdk.models.artifact import Artifact\n",
    "from ai_api_client_sdk.models.status import Status\n",
    "from ai_api_client_sdk.models.target_status import TargetStatus\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from ai_api_client_sdk.models.input_artifact_binding import InputArtifactBinding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c7cd6",
   "metadata": {},
   "source": [
    "Let's check which scenarios are available for your sound resource group. Previously we have defined some scenarios (through the provided workflow yaml files) for our resource group. We can check if they are present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29bbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_resp = ai_api_v2_client.scenario.query(resource_group)\n",
    "\n",
    "print(\"Scenarios\")\n",
    "print(\"---\" * 20)\n",
    "for idx, scenario in enumerate(scenario_resp.resources):\n",
    "    print(f\"Scenario ID {idx + 1} -> [{scenario.id}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d286ea1b",
   "metadata": {},
   "source": [
    "In order to be used, training data need to be registered as artifact in AI Core. This means specify some data parameters and associate them to an existing scenario. Below an example on how to perform this registration in the context of our exercise.\n",
    "\n",
    "\n",
    "Please, note that ai://default/data is the path to the data in S3 and \"default\" is specified in the secret object store registration. If you have specified also a pathPrefix, that will be already include in \"default\".\n",
    "\n",
    "\n",
    "The scenario id is assigned as the one specified into the training workflows (we read it from the local file, and it should match the one read by AICore from the GitHub repository). At the end of the registrazioni step, a unique id is assigned to the artifact. Once registered the artifact will appear in the \"Dataset\" section in AI Launchpad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a8829",
   "metadata": {},
   "source": [
    "NB: This step needs to be executed only when registering a new dataset, or something has changed in the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO CHANGES REQUIRED BELOW\n",
    "#\n",
    "# Load training_workflow.yaml\n",
    "training_workflow_file = '../workflows_sound/training_workflow.yaml'\n",
    "with open(training_workflow_file) as twf:\n",
    "    training_workflow = yaml.safe_load(twf)\n",
    "#\n",
    "# Load scenario id from train_workflow.yaml\n",
    "scenario_id = training_workflow['metadata']['labels']['scenarios.ai.sap.com/id']\n",
    "#\n",
    "# Set the artifact configuration\n",
    "artifact = {\n",
    "        \"name\": \"sound-data\", # Modifiable name\n",
    "        \"kind\": Artifact.Kind.DATASET,\n",
    "        \"url\": \"ai://default/data\", #default is \n",
    "        \"description\": \"Cutting machine sound clips for defect detection\",\n",
    "        \"scenario_id\": scenario_id\n",
    "    }\n",
    "# Store the artifact response to retrieve the id for the training configuration\n",
    "artifact_resp = ai_api_v2_client.artifact.create(**artifact)\n",
    "print(f\"Artifacts registered for {scenario_id} scenario!\")\n",
    "pprint(vars(artifact_resp))\n",
    "#\n",
    "# Checks if the message contains expected string\n",
    "assert artifact_resp.message == 'Artifact acknowledged'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848075f7",
   "metadata": {},
   "source": [
    "In order to train our model, we need to create a training configuration in AICore. A configuration convey several information about the training:\n",
    "\n",
    "- the name of the configuration itself;\n",
    "- the name that will indetify the input data inside AICore (it is assigned in the workflow);\n",
    "- the name that will identify the training executable in AICore (it is assigned in the workflow);\n",
    "- the id of the related scenario\n",
    "\n",
    "At the end of the configuration step, a unique id is assigned to the configuration. Once created the configuration will appear in the \"Configuration\" section in AI Launchpad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f1aae",
   "metadata": {},
   "source": [
    "NB: Also in this case, the configuration is created one time, unless something has changed or you need to execute another training on a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_artifact_name = training_workflow['spec']['templates'][0]['inputs']['artifacts'][0]['name']\n",
    "executable_name = training_workflow['metadata']['name']\n",
    "\n",
    "artifact_binding = {\n",
    "    \"key\": input_artifact_name,\n",
    "    \"artifact_id\": artifact_resp.id\n",
    "}\n",
    "\n",
    "train_configuration = {\n",
    "    \"name\": \"sound-training-configuration\",\n",
    "    \"scenario_id\": scenario_id,\n",
    "    \"executable_id\": executable_name,\n",
    "    \"parameter_bindings\": [],\n",
    "    \"input_artifact_bindings\": [ InputArtifactBinding(**artifact_binding) ]\n",
    "}\n",
    "\n",
    "# store the configuration response to access the id to create an execution\n",
    "train_config_resp = ai_api_v2_client.configuration.create(**train_configuration)\n",
    "pprint(vars(train_config_resp))\n",
    "\n",
    "assert train_config_resp.message == 'Configuration created'\n",
    "\n",
    "print(\"Configuration created for running the training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0576ac",
   "metadata": {},
   "source": [
    "Once the configuration is created, we are ready to creare an execution that will be immediatly launched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ef445",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_resp = ai_api_v2_client.execution.create(train_config_resp.id)\n",
    "pprint(vars(execution_resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa158f",
   "metadata": {},
   "source": [
    "The following code provide information about the training status. The training status can be also checked in AI Launchpad under the \"Execution\" sections.\n",
    "\n",
    "Please, note that the execution is performed inside the docker image previosly prepared and loaded in the Docker repository. The information needed to access the Docker training image are specified inside the training workflow file loaded in GitHub which AICore is synchronized with.\n",
    "\n",
    "Once the training is complete, a model is saved and it becomes available under the AI Launchpad \"Models\" section for deploying a serving artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35210f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = None\n",
    "while status != Status.COMPLETED and status != Status.DEAD:\n",
    "    # Sleep for 5 secs to avoid overwhelming the API with requests\n",
    "    time.sleep(5)\n",
    "    # Clear outputs to reduce clutter\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    execution = ai_api_v2_client.execution.get(execution_resp.id)\n",
    "    status = execution.status\n",
    "    print('...... execution status ......', flush=True)\n",
    "    print(f\"Training status: {execution.status}\")\n",
    "    print(f\"Training status details: {execution.status_details}\")\n",
    "\n",
    "\n",
    "if execution.status == Status.COMPLETED:\n",
    "    print(f\"Training complete for execution [{execution_resp.id}]!\")\n",
    "    output_artifact = execution.output_artifacts[0]\n",
    "    output = {\n",
    "        \"id\": output_artifact.id,\n",
    "        \"name\": output_artifact.name,\n",
    "        \"url\": output_artifact.url\n",
    "    }\n",
    "    with open('training_output.json', 'w') as fp:\n",
    "        json.dump(output, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5210a9",
   "metadata": {},
   "source": [
    "# Metrics and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c16cc",
   "metadata": {},
   "source": [
    "A common need is to check the performance of the training. To that it is possible to define some metrics in the training code and register them inside AiCore. This will made them available once the training is complete.\n",
    "\n",
    "Below some example about how to retrieve the metrics from AICore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_string = \"executionId eq '\" + execution_resp.id + \"'\"\n",
    "metric_resp = ai_api_v2_client.metrics.query(execution_ids=execution_resp.id)\n",
    "\n",
    "for m in metric_resp.resources:\n",
    "    for metric in m.metrics:\n",
    "        print(metric.name)\n",
    "        print(metric.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe782d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "for m in metric_resp.resources:\n",
    "    for custom_info in m.custom_info:\n",
    "        #print(custom_info.name)\n",
    "        #print(custom_info.value)\n",
    "        all_metrics.append(custom_info.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = ast.literal_eval(all_metrics[0])\n",
    "confusion_matrix = ast.literal_eval(all_metrics[1])\n",
    "#print(training_metrics[0].get(\"loss\"))\n",
    "#print(confusion_matrix[0].get(\"actual label - 0\"))\n",
    "#print(confusion_matrix[1].get(\"actual label - 1\"))\n",
    "\n",
    "a = confusion_matrix[0].get(\"actual label - 0\")\n",
    "b = confusion_matrix[1].get(\"actual label - 1\")\n",
    "\n",
    "a = [int(x) for x in re.split('[^0-9]', a) if x]\n",
    "b = [int(x) for x in re.split('[^0-9]', b) if x]\n",
    "#print(a)\n",
    "#print(b)\n",
    "\n",
    "cnf_matrix = np.array([a, b])\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeeb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "a = ast.literal_eval(training_metrics[0].get(\"loss\"))\n",
    "b = ast.literal_eval(training_metrics[1].get(\"val_loss\"))\n",
    "c = ast.literal_eval(training_metrics[2].get(\"accuracy\"))\n",
    "d = ast.literal_eval(training_metrics[3].get(\"val_accuracy\"))\n",
    "\n",
    "axs[0].plot(a)\n",
    "axs[0].plot(b)\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "axs[1].plot(c)\n",
    "axs[1].plot(d)\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ba0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"normaly\",\"anomaly\"], normalize=True,\n",
    "                      title='Confusion matrix with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a8ae8",
   "metadata": {},
   "source": [
    "# Deploy ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede87fb6",
   "metadata": {},
   "source": [
    "The model deployment is aimed at the creation and the deployment of a serving API (or artifact) that can be called to perform the inference step on some data.\n",
    "\n",
    "To do that, first one needs to provide a piece of code where it is specified the behaviour of the artifact and a proper environment where the serving artifact can run. Assuming the code has been developed, one has to create a proper Docker image for running the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b849b",
   "metadata": {},
   "source": [
    "In order to prepare the docker image with the proper content, a Docker file and a requirement.txt file have to be prepared. Then the image needs to be built and uploaded with the following commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49336ebc",
   "metadata": {},
   "source": [
    "- docker build -t YOUR_DOCKER_REPO/sound-serve:0.0.1 .\n",
    "- docker push docker.io/YOUR_DOCKER_REPO/sound-serve:0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_workflow_file = '../workflows_sound/serving_workflow_tutorial.yaml'\n",
    "with open(serving_workflow_file) as swf:\n",
    "    serving_workflow = yaml.safe_load(swf)\n",
    "\n",
    "scenario_id = serving_workflow['metadata']['labels']['scenarios.ai.sap.com/id']\n",
    "input_artifact_name = serving_workflow['spec']['inputs']['artifacts'][0]['name']\n",
    "executable_name = serving_workflow['metadata']['name']\n",
    "\n",
    "training_output = 'training_output.json'\n",
    "with open(training_output) as to:\n",
    "    serving_input = json.load(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ef27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_binding = {\n",
    "    \"key\": input_artifact_name,\n",
    "    \"artifact_id\": serving_input[\"id\"]\n",
    "}\n",
    "\n",
    "serve_configuration = {\n",
    "    \"name\": \"dev-tutorial-serving-configuration\",\n",
    "    \"scenario_id\": scenario_id,\n",
    "    \"executable_id\": executable_name,\n",
    "    \"parameter_bindings\": [],\n",
    "    \"input_artifact_bindings\": [ InputArtifactBinding(**artifact_binding) ]\n",
    "}\n",
    "\n",
    "serve_config_resp = ai_api_v2_client.configuration.create(**serve_configuration)\n",
    "\n",
    "assert serve_config_resp.message == 'Configuration created'\n",
    "\n",
    "pprint(vars(serve_config_resp))\n",
    "print(\"configuration for serving the model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_resp = ai_api_v2_client.deployment.create(serve_config_resp.id)\n",
    "pprint(vars(deployment_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d478829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll deployment status\n",
    "status = None\n",
    "while status != Status.RUNNING and status != Status.DEAD:\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
    "    status = deployment.status\n",
    "    print('...... deployment status ......', flush=True)\n",
    "    print(deployment.status)\n",
    "    pprint(deployment.status_details)\n",
    "\n",
    "    if deployment.status == Status.RUNNING:\n",
    "        print(f\"Deployment with {deployment_resp.id} complete!\")\n",
    "\n",
    "# Allow some time for deployment URL to get ready\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad911f",
   "metadata": {},
   "source": [
    "# Using deployed ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e6d50",
   "metadata": {},
   "source": [
    "Let's define the local path to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path_normal_sounds = glob.glob(\"../data/normal/*\")\n",
    "path_abnormal_sounds = glob.glob(\"../data/abnormal/*\")\n",
    "#print(path_normal_sounds)\n",
    "#print(path_abnormal_sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd14630",
   "metadata": {},
   "source": [
    "Let's visualize some audio clips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d70d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "def acoustic_feature_computation(clip,sr):\n",
    "    #scale, sr = librosa.load(clip)\n",
    "    scale=clip\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=scale, \n",
    "        sr=sr, \n",
    "        hop_length=512,\n",
    "        n_mels=64,\n",
    "        fmax=sr/2\n",
    "    )\n",
    "    log_mel = librosa.power_to_db(mel_spectrogram)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "    MFCCs=librosa.feature.mfcc(y=scale, sr=sr, n_mfcc=40, fmax=sr/2)\n",
    "    acoustic_features=np.concatenate((MFCCs,log_mel_spectrogram), axis=0)\n",
    "    return acoustic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157276eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_abn, sr_abn = librosa.load(path_abnormal_sounds[0])\n",
    "scale_norm, sr_norm = librosa.load(path_normal_sounds[0])\n",
    "#print(scale_abn, scale_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f20ee7",
   "metadata": {},
   "source": [
    "First let's visualize the two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18237b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_features_abn = acoustic_feature_computation(scale_abn,sr_abn)\n",
    "acoustic_features_norm = acoustic_feature_computation(scale_norm,sr_norm)\n",
    "print(acoustic_features_abn.shape)\n",
    "print(acoustic_features_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c006d9",
   "metadata": {},
   "source": [
    "Abnormal sound clip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a7c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pcolor(acoustic_features_abn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75b0e3",
   "metadata": {},
   "source": [
    "Normal sound clip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba118ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(acoustic_features_norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd7c32",
   "metadata": {},
   "source": [
    "In order to perform the inference step, let's transform one of the sound clips into a string (this will constitute  the body of the API call):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664920f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64encode\n",
    "import base64\n",
    "import io\n",
    "from json import dumps\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "# first: reading the binary stuff\n",
    "# note the 'rb' flag\n",
    "# result: bytes\n",
    "with open(path_abnormal_sounds[0], 'rb') as open_file:\n",
    "    byte_content = open_file.read()\n",
    "\n",
    "# second: base64 encode read data\n",
    "# result: bytes (again)\n",
    "base64_bytes = b64encode(byte_content)\n",
    "\n",
    "# third: decode these bytes to text\n",
    "# result: string (in utf-8)\n",
    "base64_string = base64_bytes.decode(ENCODING)\n",
    "\n",
    "# optional: doing stuff with the data\n",
    "# result here: some dict\n",
    "raw_data = {\"sound\": base64_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"sounds.txt\", \"w\")\n",
    "f.write(base64_string)\n",
    "f.close()\n",
    "#print(base64_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ded1b9",
   "metadata": {},
   "source": [
    "Let's make a call to the API for retrieving the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd42270",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{deployment.deployment_url}/v1/models/soundmodel:predict\"\n",
    "print(endpoint)\n",
    "\n",
    "headers = {\"Authorization\": ai_api_v2_client.rest_client.get_token(),\n",
    "           'ai-resource-group': resource_group,\n",
    "           \"Content-Type\": \"application/json\"}\n",
    "response = requests.post(endpoint, headers=headers, json=raw_data)\n",
    "\n",
    "print('Inference result:', response.json())\n",
    "#pprint(vars(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f1de5",
   "metadata": {},
   "source": [
    "# Stop deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f48aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_resp = ai_api_v2_client.deployment.modify(deployment_resp.id,\n",
    "                                                 target_status=TargetStatus.STOPPED)\n",
    "status = None\n",
    "while status != Status.STOPPED:\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
    "    status = deployment.status\n",
    "    print('...... killing deployment ......', flush=True)\n",
    "    print(f\"Deployment status: {deployment.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
