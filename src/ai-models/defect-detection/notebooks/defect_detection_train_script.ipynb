{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3ba04062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPUT_PATH=/Users/I559573/Downloads/D2V2.0/D2V_Datasets/ImageSamples\n",
      "env: DATA_SOURCE=/Users/I559573/Downloads/D2V2.0/D2V_Datasets/ImageSamples/lgp_dataset\n"
     ]
    }
   ],
   "source": [
    "%env OUTPUT_PATH=/Users/I559573/Downloads/D2V2.0/D2V_Datasets/ImageSamples\n",
    "%env DATA_SOURCE=/Users/I559573/Downloads/D2V2.0/D2V_Datasets/ImageSamples/lgp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f53d93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:35:26,244:root:INFO - Model has not been trained yet!\n",
      "2022-02-18 09:35:26,245:root:INFO - Training classifier and saving it locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples: 24\n",
      "No. of validation examples: 23\n",
      "No. of test examples: 775\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 32s 32s/step - loss: 0.7550 - accuracy: 0.5000 - val_loss: 0.7711 - val_accuracy: 0.4348\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.6895 - accuracy: 0.5000 - val_loss: 0.6446 - val_accuracy: 0.6522\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.6295 - accuracy: 0.5417 - val_loss: 0.6655 - val_accuracy: 0.6522\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.5527 - accuracy: 0.8333 - val_loss: 0.6266 - val_accuracy: 0.6522\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.5016 - accuracy: 0.7917 - val_loss: 0.6543 - val_accuracy: 0.6957\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.4655 - accuracy: 0.8333 - val_loss: 0.6443 - val_accuracy: 0.6522\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.6829 - val_accuracy: 0.6522\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.4156 - accuracy: 0.8333 - val_loss: 0.6793 - val_accuracy: 0.6522\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.3847 - accuracy: 0.9167 - val_loss: 0.6938 - val_accuracy: 0.6522\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.3470 - accuracy: 0.8750 - val_loss: 0.7211 - val_accuracy: 0.6957\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.3218 - accuracy: 0.9167 - val_loss: 0.7236 - val_accuracy: 0.6522\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.2976 - accuracy: 0.8750 - val_loss: 0.7862 - val_accuracy: 0.6087\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.6522\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.2783 - accuracy: 0.8750 - val_loss: 0.8579 - val_accuracy: 0.5652\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.2755 - accuracy: 0.9167 - val_loss: 0.8214 - val_accuracy: 0.6522\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.2536 - accuracy: 0.9167 - val_loss: 0.9066 - val_accuracy: 0.6957\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.2587 - accuracy: 0.9583 - val_loss: 0.8754 - val_accuracy: 0.6522\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.2314 - accuracy: 0.9583 - val_loss: 0.9343 - val_accuracy: 0.6957\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.2061 - accuracy: 0.9583 - val_loss: 0.9244 - val_accuracy: 0.6522\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.1766 - accuracy: 0.9583 - val_loss: 0.9765 - val_accuracy: 0.7391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:44:31,106:root:INFO - Writing tokenizer into /Users/I559573/Downloads/D2V2.0/D2V_Datasets/ImageSamples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://68b3bd9a-be43-46d8-a2ba-18d091a06965/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 09:44:39,437:tensorflow:INFO - Assets written to: ram://68b3bd9a-be43-46d8-a2ba-18d091a06965/assets\n",
      "2022-02-18 09:44:42,520:root:INFO - -----START INFERENCE-----\n",
      "2022-02-18 09:44:43,233:root:INFO - The input was predicted as 'Anomalous'\n",
      "2022-02-18 09:44:43,234:root:INFO - -----END INFERENCE-----\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Training script to showcase the end-to-end training and evaluation script.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "import cv2\n",
    "import joblib\n",
    "\n",
    "from os.path import exists\n",
    "from joblib import load, dump\n",
    "from os import makedirs\n",
    "from os import environ\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "FORMAT = \"%(asctime)s:%(name)s:%(levelname)s - %(message)s\"\n",
    "# Use filename=\"file.log\" as a param to logging to log to a file\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "\n",
    "class TrainSKInterface:\n",
    "    def __init__(self) -> None:\n",
    "        # Set the params for the training below\n",
    "        self.image_pipeline = None\n",
    "        self.dataset_all = None\n",
    "        self.train, self.val, self.test = None, None, None\n",
    "        self.target_classes = None\n",
    "        self.dataset_name = \"lgp_dataset\"\n",
    "        self.model_name = \"classifier_pipeline.pkl\"\n",
    "        self.output_path = environ[\"OUTPUT_PATH\"]\n",
    "        self.file_name = environ[\"DATA_SOURCE\"]\n",
    "\n",
    "\n",
    "    def create_dataset_bin(self):\n",
    "        IMG_WIDTH=224\n",
    "        IMG_HEIGHT=224\n",
    "        img_data_array = []\n",
    "        for file in os.listdir(img_folder):\n",
    "            image_path = os.path.join(img_folder, file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "            image = np.array(image)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255\n",
    "            image = image.tobytes()\n",
    "            img_data_array.append(image)\n",
    "        return img_data_array \n",
    "    \n",
    "\n",
    "    def read_dataset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reads the images file from path\n",
    "        \"\"\"\n",
    "        \n",
    "        path_img_ok = self.file_name + \"/Images/OK/\"\n",
    "        path_img_ko = self.file_name + \"/Images/NG/\"\n",
    "        \n",
    "        img_dataset_ok_bin = create_dataset_bin(path_img_ok)\n",
    "        img_dataset_ko_bin = create_dataset_bin(path_img_ko)\n",
    "\n",
    "        df_img_dataset_ok = pd.DataFrame(columns = ['image','label'])\n",
    "        df_img_dataset_ok['image'] = img_dataset_ok_bin\n",
    "        df_img_dataset_ok['label'] = 0\n",
    "        df_img_dataset_ko = pd.DataFrame(columns = ['image','label'])\n",
    "        df_img_dataset_ko['image'] = img_dataset_ko_bin\n",
    "        df_img_dataset_ko['label'] = 1\n",
    "\n",
    "        self.dataset_all = pd.concat([df_img_dataset_ok,df_img_dataset_ko], ignore_index=True)\n",
    "        self.dataset_all = df_img_dataset_all.sample(frac=1).reset_index(drop=True)\n",
    "        self.target_classes = self.dataset_all[\"label\"].unique()\n",
    "        #print(f\"No. of training examples: {self.dataset_all.shape[0]}\")\n",
    "        #print(f\"Classes: {self.target_classes}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "    def split_dataset(self) -> None:\n",
    "        \"\"\"\n",
    "        Split the dataset into train, validate and test\n",
    "\n",
    "        Raises:\n",
    "            Error: if dataset_train and dataset_test are not set\n",
    "        \"\"\"\n",
    "        if self.dataset_all is None:\n",
    "            raise Exception(\"Train or test data not set\")\n",
    "\n",
    "        #Change splitting proportions\n",
    "        self.train, self.val = train_test_split(self.dataset_all, test_size=0.97, random_state=25)\n",
    "        self.val, self.test = train_test_split(self.val, test_size=0.97, random_state=25)\n",
    "\n",
    "        #print(f\"No. of training examples: {self.train.shape[0]}\")\n",
    "        #print(f\"No. of validation examples: {self.val.shape[0]}\")\n",
    "        #print(f\"No. of test examples: {self.test.shape[0]}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def convert_back(self):\n",
    "        \n",
    "        temp_arr = []\n",
    "        for i in df['image'].values:\n",
    "            a = np.frombuffer(i, dtype=np.float32)\n",
    "            a = a.reshape(224,224,3)\n",
    "            temp_arr.append(a)\n",
    "            #print(a.shape)\n",
    "            \n",
    "        return temp_arr\n",
    "\n",
    "\n",
    "    def prepare_model(self):\n",
    "    \n",
    "        base_model = tf.keras.applications.vgg16.VGG16(\n",
    "            input_shape = (224, 224, 3), # Shape of our images\n",
    "            include_top = False, # Leave out the last fully connected layer\n",
    "            weights = 'imagenet'\n",
    "        )\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "            if(layer.name == 'block4_conv1'):\n",
    "                break\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "        # Flatten the output layer to 1 dimension\n",
    "        x = layers.Flatten()(base_model.output)\n",
    "\n",
    "        # Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "        # Add a dropout rate of 0.5\n",
    "        #x = layers.Dropout(0.5)(x) #To be uncommented\n",
    "\n",
    "        # Add a final sigmoid layer with 1 node for classification output\n",
    "        x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        self.image_pipeline = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "        self.image_pipeline.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "                      loss = 'binary_crossentropy', \n",
    "                      metrics = ['accuracy']\n",
    "                     )\n",
    "        \n",
    "        #self.image_pipeline.summary()\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "    def train_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Train and save the model\n",
    "        \"\"\"\n",
    "        \n",
    "        img_train = convert_back(self.train)\n",
    "        img_val = convert_back(self.val)\n",
    "        \n",
    "        #print(len(img_train))\n",
    "        #print(len(img_test))\n",
    "        #print(len(img_val))\n",
    "        #print(img_train[0].shape)\n",
    "        #print(img_test[0].shape)\n",
    "        #print(img_val[0].shape)\n",
    "\n",
    "        self.image_pipeline.fit(\n",
    "            x=np.array(img_train, np.float32), \n",
    "            y=np.array(list(map(int,df_img_dataset_train['label'])), np.float32), \n",
    "            validation_data = (np.array(img_val, np.float32), df_img_dataset_val['label'].values)\n",
    "            #,steps_per_epoch = 100\n",
    "            ,epochs = 20 #To be changed\n",
    "        )\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def save_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the model to the local path\n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info(f\"Writing tokenizer into {self.output_path}\")\n",
    "        if not exists(self.output_path):\n",
    "            makedirs(self.output_path)\n",
    "        # Save the Tokenizer and target classes to pickle file\n",
    "        with open(f\"{self.output_path}/{self.model_name}\", \"wb\") as handle:\n",
    "            dump([self.image_pipeline, self.target_classes], handle)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def get_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Get the model if it is available locally\n",
    "        \"\"\"\n",
    "        \n",
    "        if exists(f\"{self.output_path}/{self.model_name}\"):\n",
    "            logging.info(f\"Loading classifier pipeline from {self.output_path}\")\n",
    "            with open(f\"{self.output_path}/{self.model_name}\", \"rb\") as handle:\n",
    "                [self.image_pipeline, self.target_classes] = load(handle)\n",
    "        else:\n",
    "            logging.info(f\"Model has not been trained yet!\")\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def infer_model(self) -> str:\n",
    "        \"\"\"\n",
    "        Perform an inference on the model that was trained\n",
    "        \"\"\"\n",
    "        if self.image_pipeline is None:\n",
    "            self.get_model()\n",
    "\n",
    "        infer_data = np.array(convert_back(self.test), np.float32)\n",
    "        logging.info(f\"-----START INFERENCE-----\")\n",
    "        prediction = self.image_pipeline.predict(infer_data[0:1])\n",
    "        predicted_label = \"Anomalous\" if prediction[0] > 0.5 else \"Normal\"\n",
    "        logging.info(f\"The input was predicted as '{predicted_label}'\")\n",
    "        logging.info(f\"-----END INFERENCE-----\")\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "\n",
    "    def run_workflow(self) -> None:\n",
    "        \"\"\"\n",
    "        Run the training script with all the necessary steps\n",
    "        \"\"\"\n",
    "        self.read_dataset()\n",
    "        self.split_dataset()\n",
    "            \n",
    "        self.get_model()\n",
    "        if self.image_pipeline is None:\n",
    "            # Train the model if no model is available\n",
    "            logging.info(f\"Training classifier and saving it locally\")\n",
    "            self.prepare_model()\n",
    "            self.train_model()\n",
    "            self.save_model()\n",
    "\n",
    "        self.infer_model()\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_obj = TrainSKInterface()\n",
    "    train_obj.run_workflow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efc361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
