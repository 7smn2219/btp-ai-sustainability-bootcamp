{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fc96bb",
   "metadata": {},
   "source": [
    "# Create AI API client in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ccecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src\\\n",
    "/ai-models/defect-detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import yaml\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cv2\n",
    "\n",
    "from ai_api_client_sdk.ai_api_v2_client import AIAPIV2Client\n",
    "from ai_api_client_sdk.models.artifact import Artifact\n",
    "from ai_api_client_sdk.models.status import Status\n",
    "from ai_api_client_sdk.models.target_status import TargetStatus\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from ai_api_client_sdk.models.input_artifact_binding import InputArtifactBinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf34989",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = \"defect-det\"  # Must be created before\n",
    "\n",
    "aic_service_key = root_path + \"/files/aic_service_key.json\" # ENSURE YOU HAVE THE FILE PLACED CORRECTLY\n",
    "with open(aic_service_key) as ask:\n",
    "    aic_s_k = json.load(ask)\n",
    "\n",
    "# NO CHANGES REQUIRED BELOW\n",
    "#\n",
    "ai_api_v2_client = AIAPIV2Client(\n",
    "    base_url=aic_s_k[\"serviceurls\"][\"AI_API_URL\"] + \"/v2/lm\",\n",
    "    auth_url=aic_s_k[\"url\"] + \"/oauth/token\",\n",
    "    client_id=aic_s_k['clientid'],\n",
    "    client_secret=aic_s_k['clientsecret'],\n",
    "    resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1e473",
   "metadata": {},
   "source": [
    "# Train execution of ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848075f7",
   "metadata": {},
   "source": [
    "Create a training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_artifact_name = training_workflow['spec']['templates'][0]['inputs']['artifacts'][0]['name']\n",
    "executable_name = training_workflow['metadata']['name']\n",
    "\n",
    "artifact_binding = {\n",
    "    \"key\": input_artifact_name,\n",
    "    \"artifact_id\": artifact_resp.id\n",
    "}\n",
    "\n",
    "train_configuration = {\n",
    "    \"name\": \"dev-tutorial-training-configuration\",\n",
    "    \"scenario_id\": scenario_id,\n",
    "    \"executable_id\": executable_name,\n",
    "    \"parameter_bindings\": [],\n",
    "    \"input_artifact_bindings\": [ InputArtifactBinding(**artifact_binding) ]\n",
    "}\n",
    "\n",
    "# store the configuration response to access the id to create an execution\n",
    "train_config_resp = ai_api_v2_client.configuration.create(**train_configuration)\n",
    "pprint(vars(train_config_resp))\n",
    "\n",
    "assert train_config_resp.message == 'Configuration created'\n",
    "\n",
    "print(\"Configuration created for running the training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78176fd",
   "metadata": {},
   "source": [
    "Create a training execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ef445",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_resp = ai_api_v2_client.execution.create(train_config_resp.id)\n",
    "pprint(vars(execution_resp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa158f",
   "metadata": {},
   "source": [
    "Observe the training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35210f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = None\n",
    "while status != Status.COMPLETED and status != Status.DEAD:\n",
    "    # Sleep for 5 secs to avoid overwhelming the API with requests\n",
    "    time.sleep(5)\n",
    "    # Clear outputs to reduce clutter\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    execution = ai_api_v2_client.execution.get(execution_resp.id)\n",
    "    status = execution.status\n",
    "    print('...... execution status ......', flush=True)\n",
    "    print(f\"Training status: {execution.status}\")\n",
    "    pprint(f\"Training status details: {execution.status_details}\")\n",
    "\n",
    "if execution.status == Status.COMPLETED:\n",
    "    print(f\"Training complete for execution [{execution_resp.id}]!\")\n",
    "    output_artifact = execution.output_artifacts[0]\n",
    "    output = {\n",
    "        \"id\": output_artifact.id,\n",
    "        \"name\": output_artifact.name,\n",
    "        \"url\": output_artifact.url\n",
    "    }\n",
    "    with open('training_output.json', 'w') as fp: #Save the reference to the model stored in S3\n",
    "        json.dump(output, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c962b",
   "metadata": {},
   "source": [
    "# Metrics and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f406a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_string = \"executionId eq '\" + execution_resp.id + \"'\"\n",
    "metric_resp = ai_api_v2_client.metrics.query(execution_ids=execution_resp.id)\n",
    "\n",
    "for m in metric_resp.resources:\n",
    "    for metric in m.metrics:\n",
    "        print(metric.name)\n",
    "        print(metric.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f250ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "for m in metric_resp.resources:\n",
    "    for custom_info in m.custom_info:\n",
    "        #print(custom_info.name)\n",
    "        #print(custom_info.value)\n",
    "        all_metrics.append(custom_info.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = ast.literal_eval(all_metrics[0])\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "a = ast.literal_eval(training_metrics[0].get(\"loss\"))\n",
    "b = ast.literal_eval(training_metrics[1].get(\"val_loss\"))\n",
    "c = ast.literal_eval(training_metrics[2].get(\"iou\"))\n",
    "d = ast.literal_eval(training_metrics[3].get(\"val_iou\"))\n",
    "\n",
    "axs[0].plot(a)\n",
    "axs[0].plot(b)\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].legend(['Train', 'Validation'])\n",
    "\n",
    "axs[1].plot(c)\n",
    "axs[1].plot(d)\n",
    "axs[1].title.set_text('Training IoU vs Validation IoU')\n",
    "axs[1].legend(['Train', 'Validation'])\n",
    "\n",
    "a = plt.setp(axs[0], xlabel='Epoch')\n",
    "a = plt.setp(axs[0], ylabel='Loss')\n",
    "a = plt.setp(axs[1], xlabel='Epoch')\n",
    "a = plt.setp(axs[1], ylabel='IoU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a8ae8",
   "metadata": {},
   "source": [
    "# Deploy ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_workflow_file = root_path + \"/workflows/serving_workflow_tutorial.yaml\"\n",
    "with open(serving_workflow_file) as swf:\n",
    "    serving_workflow = yaml.safe_load(swf)\n",
    "\n",
    "scenario_id = serving_workflow['metadata']['labels']['scenarios.ai.sap.com/id']\n",
    "input_artifact_name = serving_workflow['spec']['inputs']['artifacts'][0]['name']\n",
    "executable_name = serving_workflow['metadata']['name']\n",
    "\n",
    "training_output = 'training_output.json'\n",
    "with open(training_output) as to:\n",
    "    serving_input = json.load(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ef27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_binding = {\n",
    "    \"key\": input_artifact_name,\n",
    "    \"artifact_id\": serving_input[\"id\"]\n",
    "}\n",
    "\n",
    "serve_configuration = {\n",
    "    \"name\": \"dev-tutorial-serving-configuration\",\n",
    "    \"scenario_id\": scenario_id,\n",
    "    \"executable_id\": executable_name,\n",
    "    \"parameter_bindings\": [],\n",
    "    \"input_artifact_bindings\": [ InputArtifactBinding(**artifact_binding) ]\n",
    "}\n",
    "\n",
    "serve_config_resp = ai_api_v2_client.configuration.create(**serve_configuration)\n",
    "\n",
    "assert serve_config_resp.message == 'Configuration created'\n",
    "\n",
    "pprint(vars(serve_config_resp))\n",
    "print(\"configuration for serving the model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_resp = ai_api_v2_client.deployment.create(serve_config_resp.id)\n",
    "pprint(vars(deployment_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d478829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll deployment status\n",
    "status = None\n",
    "while status != Status.RUNNING and status != Status.DEAD:\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "    #deployment_resp_id = \"d82a366155be8696\"\n",
    "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
    "    #deployment = ai_api_v2_client.deployment.get(deployment_resp_id)\n",
    "    status = deployment.status\n",
    "    print('...... deployment status ......', flush=True)\n",
    "    print(deployment.status)\n",
    "    pprint(deployment.status_details)\n",
    "\n",
    "    if deployment.status == Status.RUNNING:\n",
    "        print(f\"Deployment with {deployment_resp.id} complete!\")\n",
    "        #print(f\"Deployment with {deployment_resp_id} complete!\")\n",
    "\n",
    "# Allow some time for deployment URL to get ready\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad911f",
   "metadata": {},
   "source": [
    "# Using deployed ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27959b",
   "metadata": {},
   "source": [
    "Let's define the local path to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path_normal_images = glob.glob(\"../data/Images/OK/*\")\n",
    "path_abnormal_images = glob.glob(\"../data/Images/NG/*\")\n",
    "#print(path_normal_images)\n",
    "#print(path_abnormal_images)\n",
    "\n",
    "path_img_ok = root_path + \"/data/Images/OK/\"\n",
    "path_img_ko = root_path + \"/data/Images/NG/\"\n",
    "print(path_img_ok)\n",
    "print(path_img_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "\n",
    "def create_dataset(img_folder):\n",
    "    img_data_array = []\n",
    "    for file in os.listdir(img_folder):\n",
    "            image_path = os.path.join(img_folder, file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "            image = np.array(image)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255\n",
    "            img_data_array.append(image)\n",
    "    return img_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset_ok = create_dataset(path_img_ok)\n",
    "img_dataset_ko = create_dataset(path_img_ko)\n",
    "print(len(img_dataset_ok))\n",
    "print(len(img_dataset_ko))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e5e1f",
   "metadata": {},
   "source": [
    "First let's visualize an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "plt.imshow(img_dataset_ko[0], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495fb8a4",
   "metadata": {},
   "source": [
    "In order to perform the inference step, let's transform one of the images into a string (this will constitute the body of the API call):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64encode\n",
    "import base64\n",
    "import io\n",
    "from json import dumps\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "# first: reading the binary stuff\n",
    "# note the 'rb' flag\n",
    "# result: bytes\n",
    "with open(path_normal_images[0], 'rb') as open_file:\n",
    "    byte_content = open_file.read()\n",
    "\n",
    "# second: base64 encode read data\n",
    "# result: bytes (again)\n",
    "base64_bytes = b64encode(byte_content)\n",
    "\n",
    "# third: decode these bytes to text\n",
    "# result: string (in utf-8)\n",
    "base64_string = base64_bytes.decode(ENCODING)\n",
    "\n",
    "# optional: doing stuff with the data\n",
    "# result here: some dict\n",
    "raw_data = {\"image\": base64_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"image.txt\", \"w\")\n",
    "f.write(base64_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd42270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the input for inference\n",
    "# prediciton: normal product\n",
    "\n",
    "endpoint = f\"{deployment.deployment_url}/v1/models/imagemodel:predict\"\n",
    "print(endpoint)\n",
    "\n",
    "headers = {\"Authorization\": ai_api_v2_client.rest_client.get_token(),\n",
    "           'ai-resource-group': resource_group,\n",
    "           \"Content-Type\": \"application/json\"}\n",
    "response = requests.post(endpoint, headers=headers, json=raw_data)\n",
    "\n",
    "print('Inference result:', response.json())\n",
    "#pprint(vars(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f1de5",
   "metadata": {},
   "source": [
    "# Stop deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f48aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_resp = ai_api_v2_client.deployment.modify(deployment_resp.id,\n",
    "                                                 target_status=TargetStatus.STOPPED)\n",
    "\n",
    "#deployment_resp_id = \"d835352306a37be6\"\n",
    "#delete_resp = ai_api_v2_client.deployment.modify(deployment_resp_id,\n",
    "#                                                 target_status=TargetStatus.STOPPED)\n",
    "\n",
    "status = None\n",
    "while status != Status.STOPPED:\n",
    "    time.sleep(5)\n",
    "    clear_output(wait=True)\n",
    "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
    "    #deployment = ai_api_v2_client.deployment.get(deployment_resp_id)\n",
    "    status = deployment.status\n",
    "    print('...... killing deployment ......', flush=True)\n",
    "    print(f\"Deployment status: {deployment.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7531360e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
