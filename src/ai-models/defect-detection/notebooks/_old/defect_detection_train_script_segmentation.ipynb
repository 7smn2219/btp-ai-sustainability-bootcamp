{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ba04062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPUT_PATH=/Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data\n",
      "env: DATA_SOURCE=/Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data\n"
     ]
    }
   ],
   "source": [
    "%env OUTPUT_PATH=/Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data\n",
    "%env DATA_SOURCE=/Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e72419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/I559573/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/\\\n",
    "defect-detection/notebooks/data_aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f53d93f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 15:02:40,440:root:INFO - /Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data/Images/OK/\n",
      "2022-04-10 15:02:40,441:root:INFO - /Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data/Images/NG/\n",
      "2022-04-10 15:02:40,441:root:INFO - /Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data/Masks/OK_MSK/\n",
      "2022-04-10 15:02:40,442:root:INFO - /Users/I559573/Library/CloudStorage/OneDrive-SAPSE/Documents/D2V2.0_PREP/btp-ai-core-bootcamp/src/ai-models/defect-detection/data/Masks/NG_MSK/\n",
      "2022-04-10 15:02:41,613:root:INFO - Training classifier and saving it locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples: 822\n",
      "No. of training examples: 8\n",
      "No. of validation examples: 8\n",
      "No. of test examples: 806\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9948 - iou: 0.0061 - val_loss: 0.9946 - val_iou: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Training script to showcase the end-to-end training and evaluation script.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import datetime\n",
    "import logging\n",
    "import cv2\n",
    "import joblib\n",
    "import os\n",
    "import keras\n",
    "import ast\n",
    "import random\n",
    "\n",
    "#from sapai import tracking\n",
    "from os.path import exists\n",
    "from joblib import load, dump\n",
    "from os import makedirs, environ\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.optimizers import schedules, Adamax\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.layers import Conv2D,\\\n",
    "    MaxPool2D, Conv2DTranspose, Input, Activation,\\\n",
    "    Concatenate, CenterCrop, BatchNormalization\n",
    "import tensorflow.keras.metrics as tfm\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "FORMAT = \"%(asctime)s:%(name)s:%(levelname)s - %(message)s\"\n",
    "# Use filename=\"file.log\" as a param to logging to log to a file\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "\n",
    "class IoUCustom(tfm.IoU):\n",
    "    def __init__(self, from_logits=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._from_logits = from_logits\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_new = y_true[:,:,:,0]\n",
    "        y_true_new = y_true_new[..., tf.newaxis]\n",
    "        y_pred_new = tf.argmax(y_pred, axis=-1)\n",
    "        y_pred_new = y_pred_new[..., tf.newaxis]\n",
    "        return super(tfm.IoU, self).update_state(y_true_new, y_pred_new, sample_weight)\n",
    "\n",
    "\n",
    "class TrainSKInterface:\n",
    "    def __init__(self) -> None:\n",
    "        # Set the params for the training below\n",
    "        self.image_pipeline = None\n",
    "        self.dataset_all = None\n",
    "        self.train, self.val, self.test = None, None, None\n",
    "        self.dataset_name = \"lgp_dataset\"\n",
    "        self.model_name = \"segmentation_model\"\n",
    "        self.output_path = environ[\"OUTPUT_PATH\"]\n",
    "        self.file_name = environ[\"DATA_SOURCE\"]\n",
    "        self.loss = None\n",
    "        self.val_loss = None\n",
    "        self.accuracy = None\n",
    "        self.val_accuracy = None\n",
    "        self.IMG_WIDTH = 224\n",
    "        self.IMG_HEIGHT = 224\n",
    "        self.MSK_WIDTH = 184\n",
    "        self.MSK_HEIGHT = 184\n",
    "        self.target_classes = None\n",
    "        self.training_metrics = None\n",
    "\n",
    "    \n",
    "    def create_dataset(self, img_folder, bnw, binary, width, height):\n",
    "        img_data_array = []\n",
    "        color_str = cv2.COLOR_BGR2GRAY\n",
    "        color_int = 1\n",
    "        if(bnw):\n",
    "            color_str = cv2.cv2.IMREAD_GRAYSCALE\n",
    "            color_int = 1\n",
    "        for file in sorted(os.listdir(img_folder)):\n",
    "                image_path = os.path.join(img_folder, file)\n",
    "                image = cv2.imread(image_path, color_str)\n",
    "                image = cv2.resize(image, (height, width), interpolation = cv2.INTER_AREA)\n",
    "                if(not(bnw)):\n",
    "                    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
    "                    image = clahe.apply(image)\n",
    "                    kernel = np.ones((3,3),np.uint8)\n",
    "                    image = cv2.dilate(image,kernel,iterations = 1)\n",
    "                image = np.array(image)\n",
    "                image = image.astype('float32')\n",
    "                image /= 255\n",
    "                image = np.reshape(image, (width, height, color_int))\n",
    "                if(bnw):\n",
    "                    image = cv2.threshold(image, 0, 1, cv2.THRESH_BINARY)[1]\n",
    "                if(binary):\n",
    "                    image = image.tobytes()\n",
    "                img_data_array.append(image)\n",
    "        return img_data_array\n",
    "    \n",
    "    \n",
    "    def image_transform(self, img, msk):\n",
    "        transform = A.Compose([\n",
    "            #A.RandomRotate90(),\n",
    "            A.Flip(),\n",
    "            #A.Transpose(),\n",
    "            #A.OneOf([\n",
    "            #    A.MotionBlur(p=.2),\n",
    "            #    A.MedianBlur(blur_limit=3, p=0.3),\n",
    "            #    A.Blur(blur_limit=3, p=0.1),\n",
    "            #], p=0.2),\n",
    "            #A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "            #A.OneOf([\n",
    "            #    A.OpticalDistortion(p=0.3),\n",
    "            #    A.GridDistortion(p=.1),\n",
    "            #], p=0.2),\n",
    "            A.OneOf([\n",
    "                #A.CLAHE(clip_limit=2),\n",
    "                A.RandomBrightnessContrast(),            \n",
    "            ], p=0.3),\n",
    "            #A.HueSaturationValue(p=0.3),\n",
    "        ])\n",
    "        transformed = transform(image=img, mask=msk)\n",
    "        return transformed['image'], transformed['mask']\n",
    "\n",
    "\n",
    "    def data_aug(self, img_list, msk_list):\n",
    "        img_newlist = []\n",
    "        msk_newlist = []\n",
    "        for i in range(len(img_list)):\n",
    "            img, msk = self.image_transform(img_list[i], msk_list[i])\n",
    "            img_newlist.append(img)\n",
    "            msk_newlist.append(msk)\n",
    "        return img_newlist, msk_newlist\n",
    "\n",
    "\n",
    "    def read_dataset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reads the images file from path\n",
    "        \"\"\"\n",
    "        \n",
    "        path_img_ok = self.file_name + \"/Images/OK/\"\n",
    "        path_img_ko = self.file_name + \"/Images/NG/\"\n",
    "        path_msk_ok = self.file_name + \"/Masks/OK_MSK/\"\n",
    "        path_msk_ko = self.file_name + \"/Masks/NG_MSK/\"\n",
    "        \n",
    "        logging.info(f\"{path_img_ok}\")\n",
    "        logging.info(f\"{path_img_ko}\")\n",
    "        logging.info(f\"{path_msk_ok}\")\n",
    "        logging.info(f\"{path_msk_ko}\")\n",
    "        \n",
    "        img_dataset_ok_bin = self.create_dataset(path_img_ok, False, True, self.IMG_WIDTH, self.IMG_HEIGHT)\n",
    "        img_dataset_ko_bin = self.create_dataset(path_img_ko, False, True, self.IMG_WIDTH, self.IMG_HEIGHT)\n",
    "        msk_dataset_ok_bin = self.create_dataset(path_msk_ok, True, True, self.MSK_WIDTH, self.MSK_HEIGHT)\n",
    "        msk_dataset_ko_bin = self.create_dataset(path_msk_ko, True, True, self.MSK_WIDTH, self.MSK_HEIGHT)\n",
    "\n",
    "        df_img_dataset_ok = pd.DataFrame(columns = ['image','label'])\n",
    "        df_img_dataset_ok['image'] = img_dataset_ok_bin\n",
    "        df_img_dataset_ok['label'] = 0\n",
    "        df_img_dataset_ko = pd.DataFrame(columns = ['image','label'])\n",
    "        df_img_dataset_ko['image'] = img_dataset_ko_bin\n",
    "        df_img_dataset_ko['label'] = 1\n",
    "        \n",
    "        df_msk_dataset_ok = pd.DataFrame(columns = ['mask'])\n",
    "        df_msk_dataset_ok['mask'] = msk_dataset_ok_bin\n",
    "        df_msk_dataset_ko = pd.DataFrame(columns = ['mask'])\n",
    "        df_msk_dataset_ko['mask'] = msk_dataset_ko_bin\n",
    "\n",
    "        df_img_dataset_tot = pd.concat([df_img_dataset_ok,df_img_dataset_ko], ignore_index=True)\n",
    "        df_msk_dataset_tot = pd.concat([df_msk_dataset_ok,df_msk_dataset_ko], ignore_index=True)\n",
    "        \n",
    "        self.dataset_all = pd.merge(df_img_dataset_tot, df_msk_dataset_tot, left_index=True, right_index=True)\n",
    "        self.dataset_all = self.dataset_all.sample(frac=1).reset_index(drop=True)\n",
    "        print(f\"No. of training examples: {self.dataset_all.shape[0]}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "    def split_dataset(self) -> None:\n",
    "        \"\"\"\n",
    "        Split the dataset into train, validate and test\n",
    "\n",
    "        Raises:\n",
    "            Error: if dataset_train and dataset_test are not set\n",
    "        \"\"\"\n",
    "        if self.dataset_all is None:\n",
    "            raise Exception(\"Train or test data not set\")\n",
    "\n",
    "        #Change splitting proportions\n",
    "        self.train, self.val = train_test_split(self.dataset_all, test_size=0.99, random_state=25)\n",
    "        self.val, self.test = train_test_split(self.val, test_size=0.99, random_state=25)\n",
    "\n",
    "        print(f\"No. of training examples: {self.train.shape[0]}\")\n",
    "        print(f\"No. of validation examples: {self.val.shape[0]}\")\n",
    "        print(f\"No. of test examples: {self.test.shape[0]}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def convert_back(self, df, category, color_int, width, height):\n",
    "        temp_arr = []\n",
    "        for i in df[category].values:\n",
    "            a = np.frombuffer(i, dtype=np.float32)\n",
    "            a = a.reshape(width,height,color_int)\n",
    "            temp_arr.append(a)\n",
    "            #print(a.shape)\n",
    "        return temp_arr\n",
    "\n",
    "    \n",
    "    def conv_block(self, x, filters, last_block):\n",
    "        '''\n",
    "            U-Net convolutional block.\n",
    "            Used for downsampling in the contracting path.\n",
    "        '''\n",
    "        config = self.configuration()\n",
    "\n",
    "        # First Conv segment\n",
    "        x = Conv2D(filters, (3, 3),\\\n",
    "            kernel_initializer=config.get(\"initializer\"))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Second Conv segment\n",
    "        x = Conv2D(filters, (3, 3),\\\n",
    "            kernel_initializer=config.get(\"initializer\"))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Keep Conv output for skip input\n",
    "        skip_input = x\n",
    "\n",
    "        # Apply pooling if not last block\n",
    "        if not last_block:\n",
    "            x = MaxPool2D((2, 2), strides=(2,2))(x)\n",
    "\n",
    "        return x, skip_input\n",
    "    \n",
    "    \n",
    "    def compute_number_of_filters(self, block_number):\n",
    "        '''\n",
    "        Compute the number of filters for a specific\n",
    "        U-Net block given its position in the contracting path.\n",
    "        '''\n",
    "        return self.configuration().get(\"num_filters_start\") * (2 ** block_number)\n",
    "    \n",
    "    \n",
    "    def contracting_path(self, x):\n",
    "        '''\n",
    "            U-Net contracting path.\n",
    "            Initializes multiple convolutional blocks for \n",
    "            downsampling.\n",
    "        '''\n",
    "        config = self.configuration()\n",
    "\n",
    "        # Compute the number of feature map filters per block\n",
    "        num_filters = [self.compute_number_of_filters(index)\\\n",
    "                for index in range(config.get(\"num_unet_blocks\"))]\n",
    "\n",
    "        # Create container for the skip input Tensors\n",
    "        skip_inputs = []\n",
    "\n",
    "        # Pass input x through all convolutional blocks and\n",
    "        # add skip input Tensor to skip_inputs if not last block\n",
    "        for index, block_num_filters in enumerate(num_filters):\n",
    "\n",
    "            last_block = index == len(num_filters)-1\n",
    "            x, skip_input = self.conv_block(x, block_num_filters,\\\n",
    "                last_block)\n",
    "\n",
    "            if not last_block:\n",
    "                skip_inputs.append(skip_input)\n",
    "\n",
    "        return x, skip_inputs\n",
    "    \n",
    "    \n",
    "    def upconv_block(self, x, filters, skip_input, last_block = False):\n",
    "        '''\n",
    "            U-Net upsampling block.\n",
    "            Used for upsampling in the expansive path.\n",
    "        '''\n",
    "        config = self.configuration()\n",
    "\n",
    "        # Perform upsampling\n",
    "        x = Conv2DTranspose(filters//2, (2, 2), strides=(2, 2),\\\n",
    "            kernel_initializer=config.get(\"initializer\"))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        shp = x.shape\n",
    "\n",
    "        # Crop the skip input, keep the center\n",
    "        cropped_skip_input = CenterCrop(height = x.shape[1],\\\n",
    "            width = x.shape[2])(skip_input)\n",
    "\n",
    "        # Concatenate skip input with x\n",
    "        concat_input = Concatenate(axis=-1)([cropped_skip_input, x])\n",
    "\n",
    "        # First Conv segment\n",
    "        x = Conv2D(filters//2, (3, 3),\n",
    "            kernel_initializer=config.get(\"initializer\"))(concat_input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Second Conv segment\n",
    "        x = Conv2D(filters//2, (3, 3),\n",
    "            kernel_initializer=config.get(\"initializer\"))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Prepare output if last block\n",
    "        if last_block:\n",
    "            x = Conv2D(config.get(\"num_filters_end\"), (1, 1),\n",
    "                kernel_initializer=config.get(\"initializer\"))(x)\n",
    "            x = Activation(\"softmax\")(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def expansive_path(self, x, skip_inputs):\n",
    "        '''\n",
    "            U-Net expansive path.\n",
    "            Initializes multiple upsampling blocks for upsampling.\n",
    "        '''\n",
    "        num_filters = [self.compute_number_of_filters(index)\\\n",
    "                for index in range(self.configuration()\\\n",
    "                    .get(\"num_unet_blocks\")-1, 0, -1)]\n",
    "\n",
    "        skip_max_index = len(skip_inputs) - 1\n",
    "\n",
    "        for index, block_num_filters in enumerate(num_filters):\n",
    "            skip_index = skip_max_index - index\n",
    "            last_block = index == len(num_filters)-1\n",
    "            x = self.upconv_block(x, block_num_filters,\\\n",
    "                skip_inputs[skip_index], last_block)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def build_unet(self):\n",
    "        ''' Construct U-Net. '''\n",
    "        config = self.configuration()\n",
    "        input_shape = (config.get(\"input_height\"),\\\n",
    "            config.get(\"input_width\"), config.get(\"input_dim\"))\n",
    "\n",
    "        # Construct input layer\n",
    "        input_data = Input(shape=input_shape)\n",
    "\n",
    "        # Construct Contracting path\n",
    "        contracted_data, skip_inputs = self.contracting_path(input_data)\n",
    "\n",
    "        # Construct Expansive path\n",
    "        expanded_data = self.expansive_path(contracted_data, skip_inputs)\n",
    "\n",
    "        # Define model\n",
    "        model = Model(input_data, expanded_data, name=\"U-Net\")\n",
    "\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def init_model(self):\n",
    "        '''\n",
    "            Initialize a U-Net model.\n",
    "        '''\n",
    "        config = self.configuration()\n",
    "        self.image_pipeline = self.build_unet()\n",
    "\n",
    "        # Retrieve compilation input\n",
    "        loss_init = config.get(\"loss\")\n",
    "        metrics = config.get(\"metrics\")\n",
    "        num_epochs = config.get(\"num_epochs\")\n",
    "\n",
    "        # Init optimizer\n",
    "        optimizer_init = config.get(\"optimizer\")(learning_rate = 1e-3)\n",
    "\n",
    "        # Compile the model\n",
    "        self.image_pipeline.compile(loss=loss_init, optimizer=optimizer_init, metrics=metrics)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def iou_loss(self, y_true, y_pred):\n",
    "        y_pred_new = y_pred[:,:,:,1:]\n",
    "        num = tf.reduce_sum(y_true * y_pred_new)\n",
    "        den = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred_new) - num\n",
    "\n",
    "        return (1-tf.math.divide_no_nan(num,den))\n",
    "    \n",
    "\n",
    "    def configuration(self):\n",
    "        ''' Get configuration. '''\n",
    "\n",
    "        return dict(\n",
    "            num_filters_start = 64,\n",
    "            num_unet_blocks = 3,\n",
    "            num_filters_end = 2,\n",
    "            input_width = 224,\n",
    "            input_height = 224,\n",
    "            mask_width = 184,\n",
    "            mask_height = 184,\n",
    "            input_dim = 1,\n",
    "            optimizer = Adamax,\n",
    "            loss = self.iou_loss,\n",
    "            initializer = HeNormal(),\n",
    "            batch_size = 20,\n",
    "            num_epochs = 100,\n",
    "            metrics = [IoUCustom(num_classes=2, target_class_ids=[1], name='iou')]\n",
    "        )\n",
    "\n",
    "\n",
    "    def train_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Train and save the model\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "        \n",
    "        img_train = self.convert_back(self.train, 'image', 1, self.IMG_WIDTH, self.IMG_HEIGHT)\n",
    "        img_val = self.convert_back(self.val, 'image', 1, self.IMG_WIDTH, self.IMG_HEIGHT)\n",
    "        msk_train = self.convert_back(self.train, 'mask', 1, self.MSK_WIDTH, self.MSK_HEIGHT)\n",
    "        msk_val = self.convert_back(self.val, 'mask', 1, self.MSK_WIDTH, self.MSK_HEIGHT)\n",
    "        \n",
    "        img_train_aug_1, msk_train_aug_1 = self.data_aug(img_train, msk_train)\n",
    "        img_train_aug_2, msk_train_aug_2 = self.data_aug(img_train, msk_train)\n",
    "        img_train_aug = img_train + img_train_aug_1 + img_train_aug_2\n",
    "        msk_train_aug = msk_train + msk_train_aug_1 + msk_train_aug_2\n",
    "\n",
    "        temp = list(zip(img_train_aug, msk_train_aug))\n",
    "        random.shuffle(temp)\n",
    "        img_train_shuffle = [i for i,j in temp]\n",
    "        msk_train_shuffle = [j for i,j in temp]\n",
    "        #print(len(img_train_shuffle))\n",
    "        #print(len(msk_train_shuffle))\n",
    "        \n",
    "        #for i in range(len(img_val)):\n",
    "            #fig, axs = plt.subplots(1, 2, figsize=(20,10))\n",
    "            #axs[0].imshow(img_val[i], interpolation='nearest')\n",
    "            #axs[1].imshow(msk_val[i], interpolation='nearest')\n",
    "            \n",
    "            #axs[0].imshow(img_train[i], interpolation='nearest')\n",
    "            #axs[1].imshow(img_train_shuffle[i], interpolation='nearest')\n",
    "            #axs[2].imshow(msk_train[i], interpolation='nearest')\n",
    "            #axs[3].imshow(msk_train_shuffle[i], interpolation='nearest')\n",
    "            #filename_img = root_path+\"/img_\"+str(i)+\".bmp\"\n",
    "            #filename_msk = root_path+\"/msk_\"+str(i)+\".bmp\"\n",
    "            #cv2.imwrite(filename_img, np.array(img_train_shuffle[i]*255, np.uint8))\n",
    "            #cv2.imwrite(filename_msk, np.array(msk_train_shuffle[i]*255, np.uint8))\n",
    "        \n",
    "        # Load config\n",
    "        config = self.configuration()\n",
    "        batch_size = config.get(\"batch_size\")\n",
    "        validation_sub_splits = config.get(\"validation_sub_splits\")\n",
    "        num_epochs = config.get(\"num_epochs\")\n",
    "\n",
    "        # Initialize model\n",
    "        self.init_model()\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss', #Change to val_loss once in AICore\n",
    "            factor=0.2,\n",
    "            patience=20,\n",
    "            min_lr=1e-6,\n",
    "            min_delta=0.0001,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        history = self.image_pipeline.fit(\n",
    "            x=np.array(img_train, np.float32) \n",
    "            ,y=np.array(msk_train, np.float32)\n",
    "            ,epochs=1\n",
    "            #,batch_size=batch_size\n",
    "            #,steps_per_epoch=STEPS_PER_EPOCH\n",
    "            #,validation_steps=VALIDATION_STEPS\n",
    "            ,validation_data=(np.array(img_val, np.float32), np.array(msk_val, np.float32))\n",
    "            #,callbacks=[reduce_lr]\n",
    "        )\n",
    "        \n",
    "        self.loss = history.history['loss']\n",
    "        self.val_loss = history.history['val_loss']\n",
    "        self.accuracy = history.history['iou']\n",
    "        self.val_accuracy = history.history['val_iou']\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def save_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the model to the local path\n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info(f\"Writing tokenizer into {self.output_path}\")\n",
    "        if not exists(self.output_path):\n",
    "            makedirs(self.output_path)\n",
    "        # Save the Tokenizer to pickle file\n",
    "        self.image_pipeline.save(self.output_path+'/'+self.model_name)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def get_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Get the model if it is available locally\n",
    "        \"\"\"\n",
    "        \n",
    "        if exists(f\"{self.output_path}/{self.model_name}\"):\n",
    "            logging.info(f\"Loading segmentation pipeline from {self.output_path}\")\n",
    "            self.image_pipeline = models.load_model(self.output_path+'/'+self.model_name, \n",
    "                                  custom_objects = {\"iou_loss\": self.iou_loss, \"IoUCustom\": IoUCustom})\n",
    "        else:\n",
    "            logging.info(f\"Model has not been trained yet!\")\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def model_metrics(self):\n",
    "        \"\"\"\n",
    "        Perform an inference on the model that was trained\n",
    "        \"\"\"\n",
    "        if self.image_pipeline is None:\n",
    "            self.get_model()\n",
    "\n",
    "        infer_data = np.array(self.convert_back(self.val, 'image', 3, self.IMG_WIDTH, self.IMG_HEIGHT), \n",
    "                              np.float32) #Change to test sample\n",
    "        infer_masks = np.array(self.convert_back(self.val, 'mask', 1, self.MSK_WIDTH, self.MSK_HEIGHT),\n",
    "                               np.float32) #Change to test sample\n",
    "        \n",
    "        score = self.image_pipeline.evaluate(infer_data, infer_masks)\n",
    "        #print(\"Accuracy: \" + str(score[0]))\n",
    "\n",
    "        metric = [\n",
    "            {\"name\": \"Model accuracy\",\n",
    "            \"value\": float(score[1]),\n",
    "            \"labels\":[{\"name\": \"dataset\", \"value\": \"test set\"}]}\n",
    "            ]\n",
    "        #print(metric)\n",
    "        #tracking.log_metrics(metric, artifact_name = \"defect-detection\")\n",
    "        \n",
    "        self.training_metrics = [\n",
    "                    {'loss': str(self.loss)},\n",
    "                    {'val_loss': str(self.val_loss)},\n",
    "                    {'iou': str(self.accuracy)},\n",
    "                    {'val_iou': str(self.val_accuracy)}\n",
    "                ]\n",
    "        custom_info_1 = [{\"name\": \"Metrics\", \"value\": str(self.training_metrics)}]\n",
    "\n",
    "        #print(custom_info_1)\n",
    "        #tracking.set_custom_info(custom_info_1)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def visualize_metrics(self):\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "        a = ast.literal_eval(self.training_metrics[0].get(\"loss\"))\n",
    "        b = ast.literal_eval(self.training_metrics[1].get(\"val_loss\"))\n",
    "        c = ast.literal_eval(self.training_metrics[2].get(\"iou\"))\n",
    "        d = ast.literal_eval(self.training_metrics[3].get(\"val_iou\"))\n",
    "\n",
    "        axs[0].plot(a)\n",
    "        axs[0].plot(b)\n",
    "        axs[0].title.set_text('Training Loss / Validation Loss')\n",
    "        axs[0].legend(['Train', 'Validation'])\n",
    "        axs[1].plot(c)\n",
    "        axs[1].plot(d)\n",
    "        axs[1].title.set_text('Training IoU / Validation IoU')\n",
    "        axs[1].legend(['Train', 'Validation'])\n",
    "        a = plt.setp(axs[0], xlabel='Epoch')\n",
    "        a = plt.setp(axs[0], ylabel='Loss')\n",
    "        a = plt.setp(axs[1], xlabel='Epoch')\n",
    "        a = plt.setp(axs[1], ylabel='Loss')\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def display(self, display_list):\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def create_mask(self, pred_mask):\n",
    "        pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "        pred_mask = pred_mask[..., tf.newaxis]\n",
    "        pred_mask = (np.array(pred_mask, np.float32)*255).astype(np.uint8)\n",
    "        blur = cv2.GaussianBlur(pred_mask,(5,5),0)\n",
    "        ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        th3 = th3.reshape(self.MSK_WIDTH,self.MSK_HEIGHT,1)\n",
    "        return th3\n",
    "\n",
    "\n",
    "    def infer_model(self, idx):\n",
    "        \"\"\"\n",
    "        Perform an inference on the model that was trained\n",
    "        \"\"\"\n",
    "        if self.image_pipeline is None:\n",
    "            self.get_model()\n",
    "\n",
    "        infer_data = np.array(self.convert_back(self.train, 'image', 1, self.IMG_WIDTH, self.IMG_HEIGHT),\n",
    "                              np.float32) #Change to test\n",
    "        infer_masks = np.array(self.convert_back(self.train, 'mask', 1, self.MSK_WIDTH, self.MSK_HEIGHT), \n",
    "                               np.float32) #Change to test\n",
    "        \n",
    "        logging.info(f\"-----START INFERENCE-----\")\n",
    "        \n",
    "        prediction = self.image_pipeline.predict(infer_data)\n",
    "        i = idx\n",
    "        pred = self.create_mask(prediction[i])\n",
    "        a = infer_data[i]\n",
    "        b = infer_masks[i]\n",
    "        c = (np.array(pred, np.float32))\n",
    "        self.display([a, b, c])\n",
    "        \n",
    "        logging.info(f\"-----END INFERENCE-----\")\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def run_workflow(self, retrain, idx) -> None:\n",
    "        \"\"\"\n",
    "        Run the training script with all the necessary steps\n",
    "        \"\"\"\n",
    "        self.read_dataset()\n",
    "        self.split_dataset()\n",
    "        if(not(retrain)):\n",
    "            self.get_model()\n",
    "        if ((self.image_pipeline is None) or retrain):\n",
    "            # Train the model if no model is available\n",
    "            logging.info(f\"Training classifier and saving it locally\")\n",
    "            self.train_model()\n",
    "            #self.save_model()\n",
    "\n",
    "        #self.model_metrics()\n",
    "        #self.visualize_metrics()\n",
    "        #self.infer_model(idx)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def run_inference(self, idx) -> None:\n",
    "        self.read_dataset()\n",
    "        self.split_dataset()\n",
    "        self.get_model()\n",
    "        self.infer_model(idx)\n",
    "\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_obj = TrainSKInterface()\n",
    "    train_obj.run_workflow(True, 0)\n",
    "    #train_obj.run_inference(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d34b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_obj = TrainSKInterface()\n",
    "    #train_obj.run_workflow(True, 0)\n",
    "    train_obj.run_inference(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87578f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
